{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the WinoBias dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[The developer] argued with the designer becau...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The developer argued with [the designer] becau...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[The mechanic] gave the clerk a present becaus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The mechanic gave [the clerk] a present becaus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The mover] said thank you to the housekeeper ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  [The developer] argued with the designer becau...      1\n",
       "1  The developer argued with [the designer] becau...      1\n",
       "2  [The mechanic] gave the clerk a present becaus...      1\n",
       "3  The mechanic gave [the clerk] a present becaus...      1\n",
       "4  [The mover] said thank you to the housekeeper ...      1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_winobias_tsv(file_path, label):\n",
    "    df = pd.read_csv(file_path, sep='\\t', header=None, names=['id', 'text', 'orig_label'])\n",
    "    df['label'] = label\n",
    "    return df[['text', 'label']]\n",
    "\n",
    "\n",
    "pro1_df = load_winobias_tsv(\"../data/WinoBias/new/pro_stereotyped_type1.dev.tsv\", label=1)\n",
    "anti1_df = load_winobias_tsv(\"../data/WinoBias/new/anti_stereotyped_type1.dev.tsv\", label=0)\n",
    "pro2_df = load_winobias_tsv(\"../data/WinoBias/new/pro_stereotyped_type2.dev.tsv\", label=1)\n",
    "anti2_df = load_winobias_tsv(\"../data/WinoBias/new/anti_stereotyped_type2.dev.tsv\", label=0)\n",
    "pro1_df_test = load_winobias_tsv(\"../data/WinoBias/new/pro_stereotyped_type1.test.tsv\", label=1)\n",
    "anti1_df_test = load_winobias_tsv(\"../data/WinoBias/new/anti_stereotyped_type1.test.tsv\", label=0)\n",
    "pro2_df_test = load_winobias_tsv(\"../data/WinoBias/new/pro_stereotyped_type2.test.tsv\", label=1)\n",
    "anti2_df_test = load_winobias_tsv(\"../data/WinoBias/new/anti_stereotyped_type2.test.tsv\", label=0)\n",
    "train_df = pd.concat([pro1_df, pro2_df, anti1_df, anti2_df, pro1_df_test, pro2_df_test, anti1_df_test, anti2_df_test], ignore_index=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The developer] argued with the designer because [he] did not like the design. 1\n",
      "The developer argued with [the designer] because [her] idea cannot be implemented. 1\n"
     ]
    }
   ],
   "source": [
    "print(train_df.iloc[0][\"text\"], train_df.iloc[0][\"label\"])\n",
    "print(train_df.iloc[1][\"text\"], train_df.iloc[1][\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the testing and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2280\n",
      "Test size: 634\n",
      "Validation size: 254\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train size: {len(train_df)}\")\n",
    "print(f\"Test size: {len(test_df)}\")\n",
    "print(f\"Validation size: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2280/2280 [00:00<00:00, 30851.32 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 254/254 [00:00<00:00, 27543.45 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 634/634 [00:00<00:00, 33123.10 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=64)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset   = val_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset  = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "train_dataset = train_dataset.rename_column(\"label\", \"labels\")\n",
    "val_dataset   = val_dataset.rename_column(\"label\", \"labels\")\n",
    "test_dataset  = test_dataset.rename_column(\"label\", \"labels\")\n",
    "\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/charanganesh/miniforge3/envs/AI/lib/python3.10/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/k1/pg7cnkbs3fzdgsq32r3ht2_80000gn/T/ipykernel_74414/1875361171.py:34: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='429' max='429' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [429/429 02:26, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.703300</td>\n",
       "      <td>0.703061</td>\n",
       "      <td>0.492126</td>\n",
       "      <td>0.324621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.701500</td>\n",
       "      <td>0.055268</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=429, training_loss=0.4253516724823794, metrics={'train_runtime': 147.1155, 'train_samples_per_second': 46.494, 'train_steps_per_second': 2.916, 'total_flos': 224959952332800.0, 'train_loss': 0.4253516724823794, 'epoch': 3.0})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "from evaluate import load\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../models/winobias-discriminator\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")\n",
    "\n",
    "accuracy_metric = load(\"accuracy\")\n",
    "f1_metric = load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_metric.compute(predictions=preds, references=labels)\n",
    "    f1 = f1_metric.compute(predictions=preds, references=labels, average=\"weighted\")\n",
    "    return {\n",
    "        \"accuracy\": acc[\"accuracy\"],\n",
    "        \"f1\": f1[\"f1\"]\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def get_bias_score(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=64)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "        bias_score = probs[0][1].item()\n",
    "\n",
    "    return {\"text\": text, \"bias_score\": bias_score, \"prediction\": \"Biased\" if bias_score > 0.5 else \"Unbiased\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'The developer argued with the designer because he did not trust her expertise.', 'bias_score': 0.6531343460083008, 'prediction': 'Biased'}\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"The developer argued with the designer because he did not trust her expertise.\"\n",
    "print(get_bias_score(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'The developer argued with the designer because she did not trust his expertise.', 'bias_score': 0.297151654958725, 'prediction': 'Unbiased'}\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"The developer argued with the designer because she did not trust his expertise.\"\n",
    "print(get_bias_score(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'The analyst gave the assistant some documents and asked him to do the scanning', 'bias_score': 0.3200743496417999, 'prediction': 'Unbiased'}\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"The analyst gave the assistant some documents and asked him to do the scanning\"\n",
    "print(get_bias_score(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Engineers and scientists must be highly analytical and logical, so men are naturally better suited for these fields. Women, on the other hand, excel in nurturing roles like teaching and nursing.', 'bias_score': 0.7527021169662476, 'prediction': 'Biased'}\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"Engineers and scientists must be highly analytical and logical, so men are naturally better suited for these fields. Women, on the other hand, excel in nurturing roles like teaching and nursing.\"\n",
    "print(get_bias_score(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"A doctor must be attentive to their patients' needs. They should listen carefully and provide the best possible care.\", 'bias_score': 0.816252589225769, 'prediction': 'Biased'}\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"A doctor must be attentive to their patients' needs. They should listen carefully and provide the best possible care.\"\n",
    "print(get_bias_score(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'A nurse must be compassionate toward her patients. She should ensure they feel comfortable and cared for.', 'bias_score': 0.7050806283950806, 'prediction': 'Biased'}\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"A nurse must be compassionate toward her patients. She should ensure they feel comfortable and cared for.\"\n",
    "print(get_bias_score(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
